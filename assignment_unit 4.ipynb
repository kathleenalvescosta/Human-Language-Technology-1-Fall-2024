{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a25678c9993c1c2bbf0167f2ff03c982",
     "grade": false,
     "grade_id": "header-instructions",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Tips\n",
    "- To avoid unpleasant surprises, I suggest you _run all cells in their order of appearance_ (__Cell__ $\\rightarrow$ __Run All__).\n",
    "\n",
    "\n",
    "- If the changes you've made to your solution don't seem to be showing up, try running __Kernel__ $\\rightarrow$ __Restart & Run All__ from the menu.\n",
    "\n",
    "\n",
    "- Before submitting your assignment, make sure everything runs as expected. First, restart the kernel (from the menu, select __Kernel__ $\\rightarrow$ __Restart__) and then **run all cells** (from the menu, select __Cell__ $\\rightarrow$ __Run All__).\n",
    "\n",
    "## Reminder\n",
    "\n",
    "- Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name, UA email, and collaborators below:\n",
    "\n",
    "\n",
    "\n",
    "Several of the cells in this notebook are **read only** to ensure instructions aren't unintentionally altered.  \n",
    "\n",
    "If you can't edit the cell, it is probably intentional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"Kathleen Costa\"\n",
    "# University of Arizona email address\n",
    "EMAIL = \"kathleencosta@arizona.edu\"\n",
    "# Names of any collaborators.  Write N/A if none.\n",
    "COLLABORATORS = \"N/A\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0783621da2f047c6360f2ec0d56f121c",
     "grade": false,
     "grade_id": "cell-e35b85c2416e40f3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Scratchpad\n",
    "\n",
    "You are welcome to create new cells (see the __Cell__ menu) to experiment and debug your solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c80ac423030cfa372644d7cd456061af",
     "grade": false,
     "grade_id": "cell-955f8133afe96b26",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "776264c84ca2ffc29ee3695115f9945e",
     "grade": false,
     "grade_id": "cell-a2292c2fbc4cf52e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Mini Python tutorial\n",
    "\n",
    "This course uses Python 3.11.\n",
    "\n",
    "Below is a very basic (and incomplete) overview of the Python language... \n",
    "\n",
    "For those completely new to Python, [this section of the official documentation may be useful](https://docs.python.org/3.11/library/stdtypes.html#common-sequence-operations)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3eb435ae7649ab2e5de50f02ff27fd26",
     "grade": false,
     "grade_id": "cell-d6593132353238c5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h\n",
      "e\n",
      "l\n",
      "l\n",
      "o\n",
      "[2, 3, 4, 5]\n",
      "[2]\n",
      "hello, Josuke!\n",
      "Howdy, partner!\n",
      "13\n",
      "Hi, Fred!\n",
      "[('radical', 4), ('analysis', 7), ('bighorn', 12), ('bounce', 32)]\n",
      "[('analysis', 7), ('bighorn', 12), ('bounce', 32), ('radical', 4)]\n"
     ]
    }
   ],
   "source": [
    "# This is a comment.  \n",
    "# Any line starting with # will be interpreted as a comment\n",
    "\n",
    "# this is a string assigned to a variable\n",
    "greeting = \"hello\"\n",
    "\n",
    "# If enclosed in triple quotes, strings can also be multiline:\n",
    "\n",
    "\"\"\"\n",
    "I'm a multiline\n",
    "string.\n",
    "\"\"\"\n",
    "\n",
    "# let's use a for loop to print it letter by letter\n",
    "for letter in greeting:\n",
    "    print(letter)\n",
    "    \n",
    "# Did you notice the indentation there?  Whitespace matters in Python!\n",
    "\n",
    "# here's a list of integers\n",
    "\n",
    "numbers = [1, 2, 3, 4]\n",
    "\n",
    "# let's add one to each number using a list comprehension\n",
    "# and assign the result to a variable called res\n",
    "# list comprehensions are used widely in Python (they're very Pythonic!)\n",
    "\n",
    "res = [num + 1 for num in numbers]\n",
    "\n",
    "# let's confirm that it worked\n",
    "print(res)\n",
    "\n",
    "# now let's try spicing things up using a conditional to filter out all values greater than or equal to 3...\n",
    "print([num for num in res if not num >= 3])\n",
    "\n",
    "# Python 3.7 introduced \"f-strings\" as a convenient way of formatting strings using templates\n",
    "# For example ...\n",
    "name = \"Josuke\"\n",
    "\n",
    "print(f\"{greeting}, {name}!\")\n",
    "\n",
    "# f-strings are f-ing convenient!\n",
    "\n",
    "\n",
    "# let's look at defining functions in Python..\n",
    "\n",
    "def greet(name):\n",
    "    print(f\"Howdy, {name}!\")\n",
    "\n",
    "# here's how we call it...\n",
    "\n",
    "greet(\"partner\")\n",
    "\n",
    "# let's add a description of the function...\n",
    "\n",
    "def greet(name):\n",
    "    \"\"\"\n",
    "    Prints a greeting given some name.\n",
    "    \n",
    "    :param name: the name to be addressed in the greeting\n",
    "    :type name: str\n",
    "    \n",
    "    \"\"\"\n",
    "    print(f\"Howdy, {name}!\")\n",
    "    \n",
    "# I encourage you to use docstrings!\n",
    "\n",
    "# Python introduced support for optional type hints in v3.5.\n",
    "# You can read more aobut this feature here: https://docs.python.org/3.7/library/typing.html\n",
    "# let's give it a try...\n",
    "def add_six(num: int) -> int:\n",
    "    return num + 6\n",
    "\n",
    "# this should print 13\n",
    "print(add_six(7))\n",
    "\n",
    "# Python also has \"anonymous functions\" (also known as \"lambda\" functions)\n",
    "# take a look at the following code:\n",
    "\n",
    "greet_alt = lambda name: print(f\"Hi, {name}!\")\n",
    "\n",
    "greet_alt(\"Fred\")\n",
    "\n",
    "# lambda functions are often passed to other functions\n",
    "# For example, they can be used to specify how a sequence should be sorted\n",
    "# let's sort a list of pairs by their second element\n",
    "pairs = [(\"bounce\", 32), (\"bighorn\", 12), (\"radical\", 4), (\"analysis\", 7)]\n",
    "# -1 is last thing in some sequence, -2 is the second to last thing in some seq, etc.\n",
    "print(sorted(pairs, key=lambda pair: pair[-1]))\n",
    "\n",
    "# we can sort it by the first element instead\n",
    "# NOTE: python indexing is zero-based\n",
    "print(sorted(pairs, key=lambda pair: pair[0]))\n",
    "\n",
    "# You can learn more about other core data types and their methods here: \n",
    "# https://docs.python.org/3.7/library/stdtypes.html\n",
    "\n",
    "# Because of its extensive standard library, Python is often described as coming with \"batteries included\".  \n",
    "# Take a look at these \"batteries\": https://docs.python.org/3.7/library/\n",
    "\n",
    "# You now know enough to complete this homework assignment (or at least where to look)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1eaff5c27af63de92f48292a02cb8e6a",
     "grade": false,
     "grade_id": "cell-c6c4eb790c878f19",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Getting started\n",
    "\n",
    "In this assignment, you'll be implementing ...\n",
    "\n",
    "- **feature functions** to generate word and character _n_-grams\n",
    "- a `Vocabulary` class for managing features\n",
    "\n",
    "... and use them to generate **feature vectors** for words and documents.\n",
    "\n",
    "Representing words and documents as vectors is a fundamental step in statistical approaches to prediction/classification and clustering.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "885128930ee75fa7e400cf5b0aa31146",
     "grade": false,
     "grade_id": "cell-4d807c38cd18620e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Union, Iterable, Text, Tuple, Dict, Any\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9f1d8b7b6cdff48dd3aa3dea7d5c8e34",
     "grade": false,
     "grade_id": "cell-54e7e891e635594d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# `Vocabulary` class\n",
    "\n",
    "The `Vocabulary` class keeps track of our observed features and assigns each distinct feature that is tracked a unique id.  A feature's ID corresponds to its index or column in feature vectors.  The first dimension (where the index is 0) corresponds to the `<UNK>` feature which is used to represent unknown or unseen features.\n",
    "\n",
    "If you're new to defining classes in Python, please see the following video:\n",
    "\n",
    "- https://youtu.be/9yDOI2UvBtU\n",
    "\n",
    "When you're ready, implement the following methods:\n",
    "\n",
    "- `id_for(self, feature: Feature) -> int`\n",
    "- `feature_for(self, feature_id: int) -> Union[Feature, None]`\n",
    "- `create_f2i(features: Iterable[Feature]) -> Dict[Feature, int]`\n",
    "- `add_feature(self, feature: Feature) -> None`\n",
    "\n",
    "As always, use each method's docstring and accompanying tests to guide your solution.\n",
    "  \n",
    "  \n",
    "**NOTE**: functions prefixed with [`@staticmethod` do **not** need `self` as a parameter.  Treat them like regular functions.](https://docs.python.org/3.7/library/functions.html#staticmethod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4ffb05bc8ccdf055571400ad784b1306",
     "grade": false,
     "grade_id": "cell-4e23d9a009d59504",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "Feature = Union[Text, Tuple[Any, ...]]\n",
    "\n",
    "class Vocabulary:\n",
    "    \"\"\"\n",
    "    Stateful vocabulary.\n",
    "    Provides a mapping from feature to ID and a reverse mapping of ID to feature.\n",
    "    \"\"\"\n",
    "    # symbol for unknown terms    \n",
    "    UNKNOWN = \"<UNK>\"\n",
    "    \n",
    "    def __init__(self, features: Iterable[Feature]=[]):\n",
    "        \"\"\"\n",
    "        :param features: a sequence of features\n",
    "        :type features: a sequence of strings\n",
    "        \n",
    "        :Example:\n",
    "        v = Vocabulary([\"has_four_legs\", \"is_furry\", \"has_tail\"])\n",
    "        \"\"\"\n",
    "        self.f2i: Dict[Feature, int] = Vocabulary.create_f2i(features)\n",
    "        self.i2f: Dict[int, Feature] = Vocabulary.create_i2f(self.f2i)\n",
    "        \n",
    "    def id_for(self, feature: Feature) -> int:\n",
    "        \"\"\"\n",
    "        Looks up ID for feature using self.f2i.  \n",
    "        If the feature is unknown, returns -1.\n",
    "        \n",
    "        :Example:\n",
    "        \n",
    "        v = Vocabulary([\"b_feature\", \"a_feature\"])\n",
    "        assert v.id_for('<UNK>') == 0\n",
    "        assert v.id_for('a_feature') == 1\n",
    "        assert v.id_for('b_feature') == 2\n",
    "        assert v.id_for('z_feature') == -1\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        return self.f2i.get(feature, -1)\n",
    "        \n",
    "    def feature_for(self, feature_id: int) -> Union[Feature, None]:\n",
    "        \"\"\"\n",
    "        Looks up term corresponding to feature_id.  \n",
    "        If feature_id is unknown, returns None.\n",
    "        \n",
    "        :Example:\n",
    "        \n",
    "        v = Vocabulary([\"b_feature\", \"a_feature\"])\n",
    "        assert v.feature_for(0) == v.UNKNOWN\n",
    "        assert v.feature_for(1) == 'a_feature'\n",
    "        assert v.feature_for(2) == 'b_feature'\n",
    "        assert v.feature_for(19) == None\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        return self.i2f.get(feature_id, None)\n",
    "    \n",
    "    @property\n",
    "    def features(self) -> List[Feature]:\n",
    "        \"\"\"\n",
    "        @property decorator allows attribute-like use of a method:\n",
    "        \n",
    "        :Example:\n",
    "        \n",
    "        v = Vocabulary([\"has_four_legs\", \"is_furry\", \"has_tail\"])\n",
    "        assert v.features == ['<UNK>', 'has_four_legs', 'has_tail', 'is_furry']\n",
    "        \"\"\"\n",
    "        return [self.i2f[i] for i in range(len(self.i2f))]\n",
    "        \n",
    "    @staticmethod\n",
    "    def create_f2i(features: Iterable[Feature]) -> Dict[Feature, int]:\n",
    "        \"\"\"\n",
    "        Takes a flat iterable of terms and returns a dictionary of term -> int.\n",
    "        Assumes terms have already been normalized.\n",
    "\n",
    "        Requirements:\n",
    "        - First term in vocabulary (ID 0) is reserved for Vocabulary.UNKNOWN.\n",
    "        - All keys following Vocabulary.UNKNOWN should be alphabetized (a -> z).\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        features = sorted(set(features)) \n",
    "        return {Vocabulary.UNKNOWN: 0, **{feature: idx + 1 for idx, feature in enumerate(features)}}\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_i2f(f2i: Dict[Feature, int]) -> Dict[int, Feature]:\n",
    "        \"\"\"\n",
    "        Takes a dict of string -> integer and returns a reverse mapping of integer -> string.\n",
    "        \n",
    "        :Example:\n",
    "        \n",
    "        assert Vocabulary.create_i2f({\"a_feature\": 1, \"b_feature\": 2}) == {1: \"a_feature\", 2: \"b_feature\"}\n",
    "        \"\"\"\n",
    "        return {i:f for (f, i) in f2i.items()}\n",
    "\n",
    "    def add_feature(self, feature: Feature) -> None:\n",
    "        \"\"\"\n",
    "        Takes a term and updates self.f2i \n",
    "        and self.i2f if the term is not already in the vocabulary.\n",
    "\n",
    "        NOTE: add_feature only appends features.  It does not ensure the features are alphabetized after a new feature is added.\n",
    "        \n",
    "        :Example:\n",
    "        \n",
    "        v = Vocabulary([\"first_feature\"])\n",
    "        assert v.features == ['<UNK>', 'first_feature']\n",
    "        v.add_feature(\"second_feature\")\n",
    "        assert v.features == ['<UNK>', 'first_feature', 'second_feature']\n",
    "        assert v.id_for(\"second_feature\") == 2\n",
    "        \"\"\"\n",
    "        # YOUR CODE HERE\n",
    "        if feature not in self.f2i:\n",
    "            next_id = len(self.f2i)\n",
    "            self.f2i[feature] = next_id\n",
    "            self.i2f[next_id] = feature\n",
    "        \n",
    "    def __plus__(self, other):\n",
    "        \"\"\"\n",
    "        Defines what should happen when two instances of Vocabulary are summed.\n",
    "                \n",
    "        :Example:\n",
    "        \n",
    "        v1 = Vocabulary([\"first_feature\"])\n",
    "        v2 = Vocabulary([\"second_feature\"])\n",
    "        v3 = v1 + v2\n",
    "        assert len(v3) == 3\n",
    "        \"\"\"\n",
    "        if isinstance(other, Text):\n",
    "            features = self.f2i.keys() + [other]\n",
    "            return Vocabulary(features)\n",
    "        elif isinstance(other, Vocabulary):\n",
    "            features = self.f2i.keys() + other.f2i.keys()\n",
    "            return Vocabulary(features)\n",
    "        return self\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Defines what should happen when `len` is called on an instance of this class.\n",
    "        \n",
    "        :Example:\n",
    "        \n",
    "        v = Vocabulary([\"first_feature\"])\n",
    "        assert len(v) == 2\n",
    "        \"\"\"\n",
    "        return len(self.f2i)\n",
    "    \n",
    "    def __contains__(self, other):\n",
    "        \"\"\"\n",
    "        Defines what should happen when `in` is used with an instance of this class.\n",
    "        \n",
    "        :Example:\n",
    "        \n",
    "        v = Vocabulary([\"feature_1\", \"feature_2\"])\n",
    "        assert \"feature_1\" in v\n",
    "        \"\"\"\n",
    "        return True if other in self.f2i else False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9fc5aa5a04aa75a10b4b09bb73848685",
     "grade": true,
     "grade_id": "cell-72e371f90ada35b9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# requires you to implement `create_f2i`\n",
    "v = Vocabulary()\n",
    "assert len(v) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0ace8f0c26a207ace1eb33a796fd5801",
     "grade": true,
     "grade_id": "cell-adce5723aadac071",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# requires you to implement `create_f2i`\n",
    "v = Vocabulary()\n",
    "assert Vocabulary.UNKNOWN in v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffd09da94194ba1a715d3297474a68dc",
     "grade": true,
     "grade_id": "cell-6856656e99056cfa",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# requires you to implement `create_f2i`\n",
    "v = Vocabulary([\"ends_with_ly\"])\n",
    "assert len(v) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f39e467fd869c7b952b046daa6ad307",
     "grade": true,
     "grade_id": "cell-d81601eace715cd3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# requires you to implement `create_f2i`\n",
    "v = Vocabulary([\"ends_with_ly\", \"ends_with_ly\"])\n",
    "assert len(v) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "95228cbd6f162bbf883f656cb8b363ff",
     "grade": true,
     "grade_id": "cell-cda5ddd76df9a490",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# requires you to implement `create_f2i`\n",
    "v = Vocabulary()\n",
    "assert v.features == [Vocabulary.UNKNOWN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ccda65ff1cb588ab3cd2afa4161c7af6",
     "grade": true,
     "grade_id": "cell-01a982213c1219be",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# requires you to implement `create_f2i`\n",
    "v = Vocabulary()\n",
    "assert v.i2f[0] == Vocabulary.UNKNOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0b3cf408474754d53c4ff119d5e397a3",
     "grade": true,
     "grade_id": "cell-0d10542ae948c9ff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "v = Vocabulary()\n",
    "assert v.id_for(Vocabulary.UNKNOWN) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "06320ca8765ccb2de7e4d1746a29d3ae",
     "grade": true,
     "grade_id": "cell-124190febb2bf75f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "v = Vocabulary()\n",
    "# this feature shouldn't exist\n",
    "assert v.id_for(\"Xxx\") == -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60a30357fbe6045f26205ab944847b6f",
     "grade": true,
     "grade_id": "cell-06d34ceba2002381",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "v = Vocabulary()\n",
    "assert v.feature_for(0) == Vocabulary.UNKNOWN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "566ed3062057d6c6fa9f1ed44ea058e7",
     "grade": true,
     "grade_id": "cell-672c93fa5aa3287e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "v = Vocabulary()\n",
    "new_features = [\"a$\", \"^h\", \"ho\", \"ol\", \"la\", \"la\"]\n",
    "ids = set([Vocabulary.UNKNOWN])\n",
    "\n",
    "for feat in new_features:\n",
    "    v.add_feature(feat)\n",
    "    ids.add(v.id_for(feat))\n",
    "\n",
    "assert len(ids) == len(v)\n",
    "assert len(ids) == len(set(new_features)) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "20dcbf97063e7aa5780b0a17dcb64dcd",
     "grade": false,
     "grade_id": "cell-42fd0ae7a262a27d",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Feature functions\n",
    "\n",
    "Next, we'll implement a couple of feature functions to generate token and character _n_-grams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f0357edc1e47e055a229fcb8e59709da",
     "grade": false,
     "grade_id": "cell-5b50162cea507465",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## `ngrams`\n",
    "\n",
    "Generate _n_-grams for the provided tokens.\n",
    "\n",
    "**HINTS**:\n",
    "- You are expected to return a list of **tuples**.  You can turn a list into a tuple using `tuple(somelist)`.\n",
    "- Return an empty list if no _n_-grams can be generated (ex. trigrams for `[\"hello\"]` when `use_start_end=False`)\n",
    "- See https://parsertongue.org/tutorials/n-grams/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "291ed69dd07053a313a7669ea2ad65b2",
     "grade": false,
     "grade_id": "cell-fdbcfab15109a366",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def ngrams(\n",
    "    # the size of the n-gram\n",
    "    n: int, \n",
    "    tokens: List[Text], \n",
    "    use_start_end: bool = True,\n",
    "    start_symbol: Text = \"<S>\",\n",
    "    end_symbol: Text = \"</S>\"\n",
    ") -> List[Tuple[Text]]:\n",
    "    \"\"\"\n",
    "    Generates a list of n-gram tuples for the provided sequence of tokens.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    if n <= 0:\n",
    "        return []\n",
    "    \n",
    "    if use_start_end:\n",
    "        tokens = [start_symbol] * (n - 1) + tokens + [end_symbol] * (n - 1)\n",
    "\n",
    "    ngrams_list = []\n",
    "    \n",
    "    for i in range(len(tokens) - n + 1):\n",
    "        ngram = tuple(tokens[i:i + n])\n",
    "        ngrams_list.append(ngram)\n",
    "\n",
    "    return ngrams_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4bbaac00d0dbe32df00871e0c1f39e1b",
     "grade": true,
     "grade_id": "cell-297b2b18cb11e1ee",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert ngrams(n=1, tokens=[\"Good\"], use_start_end=False) == [('Good',)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0a125db6227cb98eda71b7ad74ecab44",
     "grade": true,
     "grade_id": "cell-b72ba4e4e0d68fb1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert ngrams(n=0, tokens=[\"Good\"], use_start_end=False) == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "87580d858d3614f954213142ed3b544b",
     "grade": true,
     "grade_id": "cell-d9e0151232760c5d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert ngrams(n=2, tokens=[\"Good\"], use_start_end=False) == []\n",
    "assert ngrams(n=3, tokens=[\"Good\"], use_start_end=False) == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "8ce89f9efa4314c56678f668541501cf",
     "grade": true,
     "grade_id": "cell-6745116aa7d637c2",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert ngrams(n=2, tokens=[\"Good\", \"news\"], use_start_end=False) == [('Good', 'news')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b8f10c5afaa7b0aaac4240b7b8e30b65",
     "grade": true,
     "grade_id": "cell-9de503ff7ca7f58c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert ngrams(n=2, tokens=[\"Good\"], use_start_end=True) == [('<S>', 'Good'), ('Good', '</S>')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f373b2b0d43986c913f4ebd85d74d272",
     "grade": true,
     "grade_id": "cell-826f0edc580d1098",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert ngrams(n=3, tokens=[\"Good\"], use_start_end=True) == [\n",
    "    ('<S>', '<S>', 'Good'), \n",
    "    ('<S>', 'Good', '</S>'), \n",
    "    ('Good', '</S>', '</S>')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3c876dd1d84235596f57b9b12ff92bf8",
     "grade": true,
     "grade_id": "cell-c3fa130ab0f6d964",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert ngrams(n=3, tokens=[\"Good\"], use_start_end=True, start_symbol=\"#\", end_symbol=\"#\") == [\n",
    "    ('#', '#', 'Good'), \n",
    "    ('#', 'Good', '#'), \n",
    "    ('Good', '#', '#')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "336dc061e23a5d2a87927addcb470bb0",
     "grade": true,
     "grade_id": "cell-debb1533fb3e9a4f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert ngrams(n=3, tokens=[\"Good\", \"news\", \"everyone\", \"!\"], use_start_end=True) == [\n",
    "    ('<S>', '<S>', 'Good'),\n",
    "     ('<S>', 'Good', 'news'),\n",
    "     ('Good', 'news', 'everyone'),\n",
    "     ('news', 'everyone', '!'),\n",
    "     ('everyone', '!', '</S>'),\n",
    "     ('!', '</S>', '</S>')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "45df766d0477f7b8d6a9f93decb7aaf2",
     "grade": false,
     "grade_id": "cell-a2fcb5b6c911b5a7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## `char_ngrams`\n",
    "\n",
    "Generate character _n_-grams for the provided text.\n",
    "\n",
    "**HINTS**:\n",
    "- Think about how you can make use of the `ngrams` function you implemented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "72ddf6b3b578051be8cc483f5a36554e",
     "grade": false,
     "grade_id": "cell-06af6a4d662634c9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def char_ngrams(\n",
    "    n: int, \n",
    "    text: Text,\n",
    "    use_start_end: bool = True,\n",
    "    start_symbol: Text   = \"^\",\n",
    "    end_symbol: Text     = \"$\"\n",
    ") -> List[Text]:\n",
    "    \"\"\"\n",
    "    Generates a list of n-gram tuples for the provided text.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    if n <= 0:\n",
    "        return []  \n",
    "    char_tokens = list(text)\n",
    "\n",
    "    if use_start_end:\n",
    "        char_tokens = [start_symbol] * (n - 1) + char_tokens + [end_symbol] * (n - 1)\n",
    "\n",
    "    ngrams_list = []\n",
    "    \n",
    "    for i in range(len(char_tokens) - n + 1):\n",
    "        ngram = tuple(char_tokens[i:i + n])\n",
    "        ngrams_list.append(ngram)\n",
    "\n",
    "    return ngrams_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ce80ecdcce8ecae7ffc9eb59a23709c4",
     "grade": true,
     "grade_id": "cell-edaea15571c3329b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert char_ngrams(n=-1, text=\"test\") == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2f743e71d38bd0997d1adf6e85796ec5",
     "grade": true,
     "grade_id": "cell-813881edd30ff4c3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert char_ngrams(n=2, text=\"test\") == [('^', 't'), ('t', 'e'), ('e', 's'), ('s', 't'), ('t', '$')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d82a5eb86ea454dbc21082f924310aa0",
     "grade": true,
     "grade_id": "cell-ac2a07f2cb9682ed",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert char_ngrams(n=2, text=\"test\", use_start_end=False) == [('t', 'e'), ('e', 's'), ('s', 't')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "02555eeab888887c4647eda3b50614a5",
     "grade": true,
     "grade_id": "cell-5b7048c20c2eef4b",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert char_ngrams(n=3, text=\"test\") == [\n",
    "    ('^', '^', 't'),\n",
    "    ('^', 't', 'e'),\n",
    "    ('t', 'e', 's'),\n",
    "    ('e', 's', 't'),\n",
    "    ('s', 't', '$'),\n",
    "    ('t', '$', '$')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6c208cf4028156f43da53c72869b5201",
     "grade": true,
     "grade_id": "cell-385f3971c52d1bf6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert char_ngrams(n=3, text=\"test\", use_start_end=False) == [('t', 'e', 's'), ('e', 's', 't')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f4c55661203ffe691b8f1bed668d6cf4",
     "grade": false,
     "grade_id": "cell-6d7ef8111b412b85",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Creating feature vectors\n",
    "\n",
    "Now that we've created a `Vocabulary` and some feature functions, we're ready to generate feature vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e29019b73a4294ef01130446f532d15e",
     "grade": false,
     "grade_id": "cell-ca88033a66e6373c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## `make_count_vector()`\n",
    "\n",
    "Takes a sequence of features and a `Vocabulary` and produces a feature vector of counts.\n",
    "\n",
    "**HINTS**:\n",
    "- Count occurrences of each feature.  \n",
    "- If feature is not in the vocabulary, add its occurrences to the count for the `Vocabulary.UNKNOWN` feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c3c92299a9c7b3233ceec087a3f68c4c",
     "grade": false,
     "grade_id": "cell-de3d230abb989ed2",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def make_count_vector(datum_features: Iterable[Feature], vocab: Vocabulary) -> List[int]:\n",
    "    \"\"\"\n",
    "    Converts a sequence of features to a count vector.\n",
    "    \n",
    "    Takes a datum (seq of features) and a Vocabulary instance.\n",
    "    Returns a new vector where each feature value is mapped to the count of that feature in the data\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    count_vector = [0] * len(vocab)  \n",
    "    \n",
    "    feature_counts = Counter(datum_features)\n",
    "    \n",
    "    for feature, count in feature_counts.items():\n",
    "        if feature in vocab:\n",
    "            index = vocab.id_for(feature) \n",
    "            count_vector[index] += count  \n",
    "        else:\n",
    "            unknown_index = vocab.id_for(Vocabulary.UNKNOWN)\n",
    "            count_vector[unknown_index] += count  \n",
    "    \n",
    "    return count_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "83b2dad91d7ce92ee6e9619960aa9913",
     "grade": true,
     "grade_id": "cell-639f5c7371d1a62d",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "v         = Vocabulary([\"ends_with_ly\", \"starts_with_c\", \"starts_with_g\"])\n",
    "doc_feats = [\"ends_with_ly\", \"starts_with_c\", \"starts_with_c\"]\n",
    "vector    = make_count_vector(doc_feats, v)\n",
    "\n",
    "assert len(vector) == len(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c44fad1b81461b50c5365a1d87de1651",
     "grade": true,
     "grade_id": "cell-79117930d9bc88f4",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# ensure the doc has no unknown features\n",
    "\n",
    "v         = Vocabulary([\"ends_with_ly\", \"starts_with_c\", \"starts_with_g\"])\n",
    "doc_feats = [\"ends_with_ly\", \"starts_with_c\", \"starts_with_c\"]\n",
    "vector    = make_count_vector(doc_feats, v)\n",
    "\n",
    "f_idx     = v.id_for(Vocabulary.UNKNOWN)\n",
    "assert vector[f_idx] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a91c2427757b9dcfb5b6d9fa5dedeebc",
     "grade": true,
     "grade_id": "cell-7ad313264b5945fa",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK>\t0\n",
      "ends_with_ly\t1\n",
      "starts_with_c\t2\n",
      "starts_with_g\t0\n"
     ]
    }
   ],
   "source": [
    "# ensure occurrences of features are counted\n",
    "\n",
    "v         = Vocabulary([\"ends_with_ly\", \"starts_with_c\", \"starts_with_g\"])\n",
    "doc_feats = [\"ends_with_ly\", \"starts_with_c\", \"starts_with_c\"]\n",
    "vector    = make_count_vector(doc_feats, v)\n",
    "\n",
    "for idx, feat_value in enumerate(vector):\n",
    "    print(f\"{v.feature_for(idx)}\\t{feat_value}\")\n",
    "\n",
    "f_idx     = v.id_for(\"starts_with_c\")\n",
    "assert vector   == [0, 1, 2, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "334626a855d19fe53510f83c0051275b",
     "grade": true,
     "grade_id": "cell-0642bc588c50af3d",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<UNK>\t3\n",
      "('^', 'l')\t0\n",
      "('^', 'v')\t0\n",
      "('a', 's')\t1\n",
      "('e', 's')\t0\n",
      "('l', 'a')\t0\n",
      "('s', 't')\t1\n",
      "('t', '$')\t1\n",
      "('v', 'e')\t0\n"
     ]
    }
   ],
   "source": [
    "# ensure occurrences of features are counted\n",
    "\n",
    "test      = char_ngrams(n=2, text=\"last\")\n",
    "vest      = char_ngrams(n=2, text=\"vest\")\n",
    "\n",
    "v         = Vocabulary(test + vest)\n",
    "doc_feats = char_ngrams(n=2, text=\"avast\")\n",
    "vector    = make_count_vector(doc_feats, v)\n",
    "\n",
    "for idx, feat_value in enumerate(vector):\n",
    "    print(f\"{v.feature_for(idx)}\\t{feat_value}\")\n",
    "\n",
    "assert vector == [3, 0, 0, 1, 0, 0, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `binarize_vector()`\n",
    "\n",
    "Takes a feature vector and converts it to a binary representation (i.e., each feature's value becomes either 0 or 1).\n",
    "\n",
    "**HINTS**:\n",
    "- Use 1 to represent any feature with a value $> 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "60379374a8a552fd5443a0fcebad3965",
     "grade": false,
     "grade_id": "cell-0adcdc32a1e7342d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def binarize_vector(vector: List[int]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Takes a count vector and \n",
    "    returns a new vector where each feature value is mapped to either 0 or 1\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return [1 if count > 0 else 0 for count in vector]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4e147c399d08f192c0d5e19054792ae3",
     "grade": true,
     "grade_id": "cell-e97e5dabcad37797",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert binarize_vector([3, 0, 10]) == [1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ffe7a4abe9e3e9d667e643c8d7cbb614",
     "grade": true,
     "grade_id": "cell-0b3d0d236839faeb",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert binarize_vector([1, 0, 0]) == [1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "79b1c8e0aaba973953641a870d7cbe50",
     "grade": false,
     "grade_id": "cell-6cb44e8a6ca388b8",
     "locked": true,
     "points": 6,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "# Bonus: task-specific feature functions and feature vectors\n",
    "\n",
    "Representations for words and documents are often task-specific.  Implement 3 or more feature functions that will aid in carrying out a specific task.\n",
    "\n",
    "## Option A: SPAM vs $\\neg$SPAM\n",
    "`bonus_docs` represents a toy SPAM classification dataset.  Write feature functions and use them to generate representations for each document in `bonus_docs`. \n",
    "\n",
    "## Option B: Pick your own docs and task\n",
    "Create a set of documents related to a specific task and write feature functions and use them to generate representations for each document in this set.\n",
    "\n",
    "\n",
    "### Requirements\n",
    "\n",
    "- Create at least 3 new feature functions.\n",
    "- Generate feature vectors for 3 or more documents (for example, `bonus_docs`).  \n",
    "- Describe your features.  How are they suited to the task you're modeling (ex. distinguishing between SPAM and HAM (not SPAM)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c03ddedaa7fb51ae510408fa3b6c3e09",
     "grade": false,
     "grade_id": "cell-d34873c757b09ac0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPAM\n",
      "SPAM\n",
      "NOT_SPAM\n",
      "NOT_SPAM\n",
      "NOT_SPAM\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Datum:\n",
    "    doc: Text\n",
    "    label: Text\n",
    "        \n",
    "dataset: List[Datum] = [\n",
    "    Datum(\n",
    "        # SPAM\n",
    "        doc=\"\"\"\n",
    "        FROM : \"MR.LAMIDO SANUSI\" <elvislives478@aol.com>\n",
    "        SUBJECT: Your kind Attention: Beneficiary, Call me at +2348080754902 for more information.\n",
    "        BODY:\n",
    "        My Name Is Mr. Lamido Sanusi. I Am The Governor Central Bank Of Nigeria.  This Is To Notify You That Your Over Due Inheritance Funds Has Been Gazzeted To Be Released To You Via The Foreign Remmitance Department Of Our Bank.\n",
    "\n",
    "        Meanwhile, A Woman Came To My Office Few Days Ago With A Letter, Claiming To Be Your Representative And Sent By You.  If she is not your reprsentative or sent by you, kindly respond immediately reconfirming to me the following details to avoid any mistake.\n",
    "        + Full name\n",
    "        + Full residential contact address\n",
    "        + Direct telephone number number\n",
    "        + Age and current occupation\n",
    "        + Copy of your identification if available.\n",
    "\n",
    "        However, We Shall Proceed To Issue All Payments Details To The Said Mrs. Barbara Kleihans If We Do Not Hear From You Within The Next Three Working Days From Today. Await for your prompt response\n",
    "\n",
    "        You.Regards,\n",
    "\n",
    "        Mr. Lamido Sanusi\n",
    "        \"\"\",\n",
    "        label=\"SPAM\"\n",
    "    ),\n",
    "    Datum(\n",
    "        # SPAM\n",
    "        doc=\"\"\"\n",
    "        FROM: saxquatch4life@aol.com\n",
    "        SUBJECT: You're a Winner!\n",
    "        BODY: \n",
    "        This President Zump. You've been pre-selected for early retirement. \n",
    "        Please send your social security number ASAP to claim prize.\n",
    "        \"\"\",\n",
    "        label=\"SPAM\"\n",
    "    ),\n",
    "    Datum(\n",
    "        # NOT SPAM\n",
    "        doc=\"\"\"\n",
    "        FROM: ***REDACTED***@arizona.edu\n",
    "        SUBJECT: [ling_dept_faculty] Response needed\n",
    "        BODY: \n",
    "        Please send your syllabus to ***REDACTED*** by 4PM on Friday.\n",
    "        \"\"\",\n",
    "        label=\"NOT_SPAM\"\n",
    "    ),\n",
    "    Datum(\n",
    "        # NOT SPAM\n",
    "        doc=\"\"\"\n",
    "        FROM: ***REDACTED***@arizona.edu\n",
    "        SUBJECT: Deadline extension?\n",
    "        BODY: \n",
    "        Dr. Hahn-Powell,\n",
    "\n",
    "        I hope you are well.  Is there any way I can get an extension on the homework?  \n",
    "\n",
    "        Respectfully,\n",
    "\n",
    "            ***REDACTED***\n",
    "        \"\"\",\n",
    "        label=\"NOT_SPAM\"\n",
    "    ),\n",
    "    Datum(\n",
    "        # NOT SPAM\n",
    "        doc=\"\"\"\n",
    "        FROM: drive-shares-noreply@google.com\n",
    "        SUBJECT: Internship report - Invitation to edit\n",
    "        BODY:     \n",
    "            ***REDACTED*** has invited you to edit the following document:\n",
    "\n",
    "            Internship report\n",
    "\n",
    "            Open in Docs\n",
    "\n",
    "\n",
    "        Google Docs: Create and edit documents online.\n",
    "        Google LLC, 1600 Amphitheatre Parkway, Mountain View, CA 94043, USA\n",
    "        You have received this email because medeiros@email.arizona.edu shared a document with you from Google Docs.\n",
    "        \"\"\",\n",
    "        label=\"NOT_SPAM\"\n",
    "    )\n",
    "]\n",
    "    \n",
    "for datapoint in dataset:\n",
    "    # we can access attributes of a dataclass just like any other class\n",
    "    print(datapoint.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Option B, describe the task here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If Option B, define your docs and labels here using the Datum class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "250b808f4434e4987655b434ee264e91",
     "grade": true,
     "grade_id": "bonus-feature-functions",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#N/A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c66368110d7c453568ca797e42f7154b",
     "grade": true,
     "grade_id": "bonus-feature-vectors",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "#N/A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "383cd869ec393b454c3e66783607d09b",
     "grade": true,
     "grade_id": "bonus-explanation",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of Mail: SPAM, Feature Vector: [0, 1, 1]\n",
      "Type of Mail: SPAM, Feature Vector: [1, 0, 1]\n",
      "Type of Mail: NOT_SPAM, Feature Vector: [0, 0, 0]\n",
      "Type of Mail: NOT_SPAM, Feature Vector: [0, 0, 0]\n",
      "Type of Mail: NOT_SPAM, Feature Vector: [0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def contains_exclamation(doc: str) -> int:\n",
    "    return 1 if '!' in doc else 0\n",
    "\n",
    "def contains_phone_number(doc: str) -> int:\n",
    "    pattern = r'\\+?\\d[\\d -]{7,}\\d'\n",
    "    return 1 if re.search(pattern, doc) else 0\n",
    "\n",
    "def contains_spammy_keywords(doc: str) -> int:\n",
    "    spam_keywords = ['winner', 'claim', 'urgent', 'free', 'call', 'respond']\n",
    "    return 1 if any(keyword in doc.lower() for keyword in spam_keywords) else 0\n",
    "\n",
    "def extract_features(datum: Datum) -> List[int]:\n",
    "    return [\n",
    "        contains_exclamation(datum.doc),\n",
    "        contains_phone_number(datum.doc),\n",
    "        contains_spammy_keywords(datum.doc),\n",
    "    ]\n",
    "\n",
    "feature_vectors = [extract_features(datapoint) for datapoint in dataset]\n",
    "\n",
    "for datum, vector in zip(dataset, feature_vectors):\n",
    "    print(f\"Type of Mail: {datum.label}, Feature Vector: {vector}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
